{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7eaea7-1589-4f76-8b4d-da4acb5b59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout\n",
    "from tensorflow.keras.utils import image_dataset_from_directory as idfd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5850ba3c-365f-4739-98be-fa0e0a02ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/omid/Desktop/data/'\n",
    "train_data_path = '/Users/omid/Desktop/data/Train'\n",
    "train_label_path = '/Users/omid/Desktop/data/Train_data_label.xlsx'\n",
    "test_label_path = '/Users/omid/Desktop/data/Test_data_label.xlsx'\n",
    "test_data_path = '/Users/omid/Desktop/data/Test/'\n",
    "\n",
    "#reading train labels\n",
    "\n",
    "train_labels = pd.read_excel(train_label_path)\n",
    "test_labels = pd.read_excel(test_label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086e147-2263-4910-8ea2-7c19a93d7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae566e5-8887-4639-b3ef-96fb95907105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images from directory into np array format\n",
    "\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "    \n",
    "def load_image(directory):\n",
    "    images = []\n",
    "    for x in train_labels.index:\n",
    "        image = Image.open(os.path.join(directory, train_labels.loc[x, \"Path\"]))\n",
    "        if image is not None:\n",
    "            images.append(np.array(image))\n",
    "        image.close()\n",
    "    return images\n",
    "\n",
    "def load_test(directory):\n",
    "    images = []\n",
    "    for x in os.listdir(directory):\n",
    "        try:\n",
    "            image = Image.open(os.path.join(directory, x))\n",
    "        except:\n",
    "            continue\n",
    "        if image is not None:\n",
    "            images.append(np.array(image))\n",
    "        image.close()\n",
    "    return images\n",
    "\n",
    "def load_test_wlabel(directory):\n",
    "    images = []\n",
    "    for x in test_labels.index:\n",
    "        image = Image.open(os.path.join(directory, test_labels.loc[x, \"Path\"]))\n",
    "        if image is not None:\n",
    "            images.append(np.array(image))\n",
    "        image.close()\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac3efb-10a1-4818-9a49-81fa2c56dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = load_image(data_path)\n",
    "test_images = load_test(test_data_path)\n",
    "ltest_images = load_test_wlabel(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45576357-b051-4013-acc3-3f3c954c3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db269874-68ce-4f5f-a99f-c21bc9f47259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize all images to 30x30\n",
    "def resize(train_images):\n",
    "    for x in range(len(train_images)):\n",
    "        im = Image.fromarray(train_images[x])\n",
    "        im = im.resize((30, 30))\n",
    "        train_images[x] = np.array(im)\n",
    "        im.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef9595c-beef-473a-a6bc-0aaa94ccc28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize(train_images)\n",
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3751503-fb74-4bb0-967a-73e518fd5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448403df-3d45-429f-8c8a-aa1b50dc06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turns images to grayscale for grayscale CNN model\n",
    "from skimage import color\n",
    "\n",
    "def gray_scale(train):\n",
    "    grays= []\n",
    "    for x in range(len(train)):\n",
    "        im = Image.fromarray(train[x])\n",
    "        im = ImageOps.grayscale(im)\n",
    "        t = np.array(im)\n",
    "        grays.append(t)\n",
    "        im.close()\n",
    "    return grays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe6f41-4745-41dd-a675-1d0c2371648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the color and grayscale image array in np array format\n",
    "color_img_arr = np.array(train_images)\n",
    "grayscale_img_arr = np.array(gray_scale(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa258a49-c3e9-4789-b97e-94dc6417513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target value\n",
    "y = train_labels['ClassId'].values\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715bf92-8004-4da0-99f0-edef846acbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Bar Chart of Classes from train and test data by replacing numbers with actual class names\n",
    "classes = [\"Speed limit (20km/h)\", \"Speed limit (30km/h)\", \"Speed limit (50km/h)\", \"Speed limit (60km/h)\", \"Speed limit (70km/h)\" \n",
    ", \"Speed limit (80km/h)\", \"End of speed limit (80km/h)\", \"Speed limit (100km/h)\", \"Speed limit (120km/h)\", \"No passing\", \"No passing vehicle over 3.5 tons\" \n",
    ", \"Right-of-way at the intersection\", \"Priority road\", \"Yield\", \"Stop\", \"No vehicles\", \"Vehicle > 3.5 tons prohibited\", \"No entry\", \n",
    "\"General caution\", \"Dangerous curve left\", \"Dangerous curve right\", \"Double curve\", \"Bumpy road\", \"Slippery road\", \"Road narrows on the right\", \n",
    "\"Road work\", \"Traffic signals\", \"Pedestrians\", \"Children crossing\", \"Bicycles crossing\", \"Beware of ice/snow\", \"Wild animals crossing\", \n",
    "\"End speed + passing limits\", \"Turn right ahead\", \"Turn left ahead\", \"Ahead only\", \"Go straight or right\", \"Go straight or left\", \n",
    "\"Keep right\", \"Keep left\", \"Roundabout mandatory\", \"End of no passing\", \"End no passing vehicle > 3.5 tons\"]\n",
    "\n",
    "fig = plt.figure(figsize = (25,9))\n",
    "vc = train_labels[\"ClassId\"].value_counts().sort_index()\n",
    "plt.bar(vc.index,vc.values)\n",
    "class_legend = ('\\n').join(f'{ids} - {classe}' for ids,classe in zip(vc.index,classes))\n",
    "plt.text(45, 5, class_legend)\n",
    "plt.subplots_adjust(right=.5)\n",
    "plt.xticks(vc.index)\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.title(\"Number of Images per Class in Training Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8b93f-79a3-486d-b4d5-87d83ed80b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (25,9))\n",
    "vc = test_labels[\"ClassId\"].value_counts().sort_index()\n",
    "plt.bar(vc.index,vc.values)\n",
    "class_legend = ('\\n').join(f'{ids} - {classe}' for ids,classe in zip(vc.index,classes))\n",
    "plt.text(45, 5, class_legend)\n",
    "plt.subplots_adjust(right=.5)\n",
    "plt.xticks(vc.index)\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.title(\"Number of Images per Class in Test Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e23804d-c2a8-41c8-8706-b6bb4b44e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Color Array Data into Train and Test\n",
    "CX_train, CX_val, Cy_train, Cy_val = train_test_split(color_img_arr, y, random_state=42)\n",
    "\n",
    "plt.imshow(CX_train[0])\n",
    "print(Cy_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa0b956-2451-4d54-a406-0f6bcaa4dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#create Color model\n",
    "\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(30,30,3)))\n",
    "model.add(Conv2D(32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))\n",
    "\n",
    "early_stop = EarlyStopping(patience=2, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8db3a9-96ef-4825-8949-afcbc522260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c01ab-f090-428f-a260-7907952c199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590fd3ac-d49f-4d6b-a695-094a5ea11527",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = model.fit(CX_train, Cy_train, epochs=5, validation_data=(CX_val, Cy_val), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f5807d-c36c-4d97-8998-e9818ec43e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting training and validation accuracy of Color Image CNN Model\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(colors.history['accuracy'], label='training accuracy')\n",
    "plt.plot(colors.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(1)\n",
    "plt.plot(colors.history['loss'], label='training loss')\n",
    "plt.plot(colors.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5426cf63-9e7b-4f13-96bf-aeda273acd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate with Test Data\n",
    "\n",
    "resize(test_images)\n",
    "\n",
    "CX_test = np.array(test_images)\n",
    "Cy_test = test_labels['ClassId'].values\n",
    "\n",
    "score = model.evaluate(CX_test, Cy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd585fad-f547-4425-8a75-6a7c45e1534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions with color CNN model\n",
    "\n",
    "predictions = model.predict(CX_test)\n",
    "pred_class = np.argmax(predictions, axis=1)\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433067af-b595-4534-b01a-d120766c96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(CX_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7902799-130e-4361-8fb9-a95409f866c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating Predictions\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Cy_test, pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ca8de-8595-460c-8882-6dae7990ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "GX_train, GX_val, Gy_train, Gy_val = train_test_split(grayscale_img_arr, y, random_state=42)\n",
    "\n",
    "plt.imshow(GX_train[0], cmap='gray')\n",
    "print(Gy_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9af8a-2989-4ff6-a017-4be2dd5a4ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Grayscale model\n",
    "\n",
    "gmodel = Sequential()\n",
    "#add model layers\n",
    "gmodel.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(30,30,1)))\n",
    "gmodel.add(Conv2D(32, kernel_size=(5,5), activation='relu'))\n",
    "gmodel.add(MaxPool2D(pool_size=(2, 2)))\n",
    "gmodel.add(Dropout(rate=0.25))\n",
    "gmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "gmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "gmodel.add(MaxPool2D(pool_size=(2, 2)))\n",
    "gmodel.add(Dropout(rate=0.25))\n",
    "gmodel.add(Flatten())\n",
    "gmodel.add(Dense(256, activation='relu'))\n",
    "gmodel.add(Dropout(rate=0.5))\n",
    "gmodel.add(Dense(43, activation='softmax'))\n",
    "\n",
    "early_stop = EarlyStopping(patience=2, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8aba09-17c9-42a0-ac7d-7d5da2cbd076",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmodel.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a851bd98-cbfd-4270-94ae-8c1c0a7de831",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace4cc9-82db-4330-b0b9-24061e005d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = gmodel.fit(GX_train, Gy_train, epochs=5, validation_data=(GX_val, Gy_val), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1f343-d535-40be-8839-f9a36c20c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting training and validation accuracy of Grayscale Image CNN Model\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(gray.history['accuracy'], label='training accuracy')\n",
    "plt.plot(gray.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(1)\n",
    "plt.plot(gray.history['loss'], label='training loss')\n",
    "plt.plot(gray.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc84cb3f-27b6-42ca-8b96-0ac6779270b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate with Test Data\n",
    "\n",
    "test_ig = gray_scale(test_images)\n",
    "\n",
    "GX_test = np.array(test_ig)\n",
    "Gy_test = test_labels['ClassId'].values\n",
    "\n",
    "gscore = gmodel.evaluate(GX_test, Gy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336946ab-cbc1-44b9-b0d0-dd8b3fa01a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions with Grayscale CNN model\n",
    "\n",
    "predictions_gray = gmodel.predict(GX_test)\n",
    "gpred_class = np.argmax(predictions_gray, axis=1)\n",
    "print(gpred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c019903-5c95-4abd-b44f-8d5ce56f855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(GX_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01716a5-fcfc-4394-84ee-49f808643f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating Predictions\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Gy_test, gpred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe680d6-4194-4beb-98a1-35747357c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the performance and evaluation of both the color and grayscale model, we can say the grayscale model has a higher accuracy and lower loss \n",
    "#and therefore is the better model\n",
    "\n",
    "#During both the fitting and evaluation phase the training, validation and test accuracy were higher for the grayscale model\n",
    "\n",
    "#plot compares training and validation accuracy/loss of both to visualize that the grayscale model is better\n",
    "plt.figure(0)\n",
    "plt.plot(gray.history['accuracy'], label='grayscale training accuracy')\n",
    "plt.plot(colors.history['accuracy'], label='color training accuracy')\n",
    "plt.plot(gray.history['val_accuracy'], label='grayscale val accuracy')\n",
    "plt.plot(colors.history['val_accuracy'], label='color val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(1)\n",
    "plt.plot(gray.history['loss'], label='grayscale training loss')\n",
    "plt.plot(colors.history['loss'], label='color training loss')\n",
    "plt.plot(gray.history['val_loss'], label='grayscale val loss')\n",
    "plt.plot(colors.history['val_loss'], label='color val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
